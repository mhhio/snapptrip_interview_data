FROM apache/airflow:2.7.1

USER root

# Install OpenJDK-17
RUN apt update && \
    apt-get install -y --no-install-recommends openjdk-17-jdk && \
    apt-get clean autoclean && \
    apt-get autoremove --yes && \
    rm -rf /var/lib/{apt,dpkg,cache,log}/;

# Install Spark
ENV SPARK_VERSION=3.5.1
ENV HADOOP_VERSION=3

RUN mkdir -p /opt/spark && \
    curl -sL https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz | tar -xz -C /opt/spark --strip-components=1

# Set environment variables
ENV SPARK_HOME=/opt/spark
ENV PATH=$PATH:$SPARK_HOME/bin

# Set JAVA_HOME dynamically
RUN echo "export JAVA_HOME=\$(dirname \$(dirname \$(readlink -f \$(which java))))" >> /etc/profile && \
    echo "export PATH=\$PATH:\$JAVA_HOME/bin" >> /etc/profile

USER airflow

# Install Spark provider for Airflow
RUN pip install --no-cache-dir apache-airflow-providers-apache-spark==4.8.2